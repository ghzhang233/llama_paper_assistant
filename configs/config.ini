[SELECTION]
author_match_score = 18.0
run_llama = true
run_openai = false
# DO NOT USE GPT 3.5 TURBO EXCEPT FOR DEBUGGING
# model = gpt-3.5-turbo
# model = gpt-3.5-turbo-1106
# model = gpt-4
# model = gpt-4-1106-preview
# model = Llama-2-7b-chat-hf
model = Llama-2-70b-chat-hf
# cost quality tradeoff - larger batches are cheaper but less accurate.
batch_size = 5

[FILTERING]
# arxiv_category = cs.CL,cs.LG,cs.AI
arxiv_category = cs.CL,cs.LG
# arxiv_category = cs.CL
# force_primary ignores papers that are only cross-listed into the arxiv_category
force_primary = true
# draws num_samples samples from the LM and averages scores
num_samples = 20
hcutoff = 15
relevance_cutoff = 8
novelty_cutoff = 8
# whether to do author matching
author_match = true

[OUTPUT]
output_path = _posts
# options: json, md, slack
dump_json = false
dump_md = true
push_to_slack = false
